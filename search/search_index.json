{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83d\udc4b Halo, Saya Arsan Akbar","text":"<p>Selamat datang di portofolio saya! Di sini kamu bisa menemukan berbagai proyek saya di bidang Machine Learning, Computer Vision, dan AI Engineering.</p> <p>Semua proyek di bawah terhubung langsung ke repository GitHub saya.</p>"},{"location":"projects/","title":"\ud83d\ude80 Daftar Proyek","text":"<p>Berikut beberapa proyek unggulan saya:</p> <ul> <li>Gamble Comment Detector</li> <li>Book Recommendation</li> <li>Student Performance Prediction</li> </ul>"},{"location":"projects/Book-recommendation/","title":"Laporan Proyek Machine Learning - Muh. Arsan Akbar","text":""},{"location":"projects/Book-recommendation/#project-overview","title":"Project Overview","text":"<p>Seiring dengan berkembangnya teknologi informasi, banyak aplikasi manajemen buku di perpustakaan kini telah menyediakan berbagai koleksi buku dalam format digital yang dapat diakses secara daring. Aksesibilitas ini mendorong kebutuhan akan fitur pencarian buku yang lebih cerdas, salah satunya melalui penerapan sistem rekomendasi. Sistem rekomendasi berfungsi untuk membantu pengguna menemukan buku yang sesuai dengan minat dan preferensi mereka, dengan cara memberikan saran berdasarkan masukan atau kriteria tertentu yang mereka tentukan. Seperti yang dijelaskan oleh Murti et al. (2019), sistem rekomendasi merupakan teknik yang bertujuan untuk menyarankan item pilihan yang paling relevan bagi pengguna.</p> <p>Contohnya, pada aplikasi E-Library di Perpustakaan Politeknik Negeri Banyuwangi, sistem pencarian telah dibangun untuk memudahkan pengguna dalam menemukan buku yang diinginkan. Namun, dalam praktiknya ditemukan bahwa akurasi pencarian terkadang kurang optimal. Misalnya, ketika pengguna mengetikkan kata kunci berupa judul lengkap sebuah buku, sistem tidak selalu mampu menampilkan hasil yang sesuai, bahkan menampilkan pesan \"Data Kosong\", padahal buku tersebut sebenarnya tersedia dalam basis data. Permasalahan ini menunjukkan pentingnya penggunaan metode atau algoritma pencarian yang lebih efektif untuk meningkatkan kinerja sistem rekomendasi (Sadesty Rahmadhani et al. 2024).</p> <p>Berkaitan dengan permasalahan tersebut, dalam proyek ini dilakukan pengembangan sistem rekomendasi buku berbasis Content-Based Filtering dan Collaborative Filtering menggunakan dataset Book-Crossing. Proyek ini bertujuan untuk mengoptimalkan proses pencarian dan penemuan buku, dengan memberikan rekomendasi yang lebih relevan berdasarkan konten buku maupun pola interaksi pengguna sebelumnya. Dengan pendekatan ini, diharapkan pengguna dapat menerima saran buku yang sesuai dengan preferensi mereka, meskipun tidak memasukkan kata kunci secara persis. Selain itu, proyek ini juga mengkaji penerapan model berbasis machine learning dan deep learning untuk meningkatkan akurasi serta kualitas rekomendasi yang dihasilkan.</p> <p>Referensi: </p> <p>Murti, H., Lestariningsih, E., &amp; ., S. (2019). PERANCANGAN SISTEM REKOMENDASI BUKU PADA KATALOG PERPUSTAKAAN MENGGUNAKAN PENDEKATAN CONTENT-BASED FILTERING DAN ALGORITMA FP-GROWTH. SINTAK, 3. Retrieved from https://www.unisbank.ac.id/ojs/index.php/sintak/article/view/7643</p> <p>Sadesty Rahmadhani, Lutfi Hakim, &amp; Galih Hendra Wibowo. (2024). Sistem Rekomendasi Penelusuran Buku Berbasis Content-Based Filtering dengan Pembobotan TF-RF. Jurnal Informatika Polinema, 10(4), 491\u2013500. https://doi.org/10.33795/jip.v10i4.5565</p>"},{"location":"projects/Book-recommendation/#business-understanding","title":"Business Understanding","text":""},{"location":"projects/Book-recommendation/#problem-statements","title":"Problem Statements","text":"<ul> <li>Berdasarkan data pengguna, bagaimana cara membangun sistem rekomendasi buku yang dipersonalisasi menggunakan teknik Content-Based Filtering?</li> <li>Dengan memanfaatkan data rating yang tersedia, bagaimana sistem dapat merekomendasikan buku lain yang mungkin disukai oleh pengguna dan belum pernah mereka baca sebelumnya?</li> </ul>"},{"location":"projects/Book-recommendation/#goals","title":"Goals","text":"<ul> <li>Menghasilkan rekomendasi buku yang dipersonalisasi sesuai preferensi pengguna menggunakan teknik Content-Based Filtering.</li> <li>Menghasilkan rekomendasi buku yang sesuai dengan minat pengguna dan belum pernah dibaca sebelumnya menggunakan teknik Collaborative Filtering.</li> </ul>"},{"location":"projects/Book-recommendation/#solution-approach","title":"Solution Approach","text":""},{"location":"projects/Book-recommendation/#content-based-filtering","title":"Content-Based Filtering","text":"<p>Pendekatan ini merekomendasikan buku berdasarkan kemiripan konten antara buku yang sudah diketahui disukai pengguna dengan buku lain dalam koleksi. Algoritma yang digunakan adalah Word2Vec untuk membangun representasi vektor dari fitur buku. Model kemudian dievaluasi dengan pendekatan perhitungan presisi secara manual untuk mengukur relevansi rekomendasi yang dihasilkan.</p>"},{"location":"projects/Book-recommendation/#collaborative-filtering","title":"Collaborative Filtering","text":"<p>Pendekatan ini merekomendasikan buku dengan memanfaatkan pola interaksi antar pengguna. Sistem akan mengidentifikasi pengguna lain yang memiliki pola perilaku serupa dan merekomendasikan buku-buku yang disukai oleh pengguna tersebut. Teknik yang digunakan adalah matrix factorization, khususnya metode Singular Value Decomposition (SVD), untuk memprediksi rating atau ketertarikan terhadap buku. Untuk mengoptimalkan model, dilakukan hyperparameter tuning menggunakan metode grid search, sehingga diperoleh kombinasi parameter terbaik. Evaluasi model dilakukan menggunakan metrik Root Mean Squared Error (RMSE) untuk mengukur akurasi prediksi rating.</p>"},{"location":"projects/Book-recommendation/#data-understanding","title":"Data Understanding","text":"<p>Dataset yang digunakan dalam proyek ini adalah Book-Crossing Dataset. Dataset ini berisi informasi tentang pengguna, buku, dan rating yang diberikan oleh pengguna terhadap buku. Dataset ini dapat diunduh melalui tautan berikut:  Book-Crossing Dataset atau https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset?select=Ratings.csv</p>"},{"location":"projects/Book-recommendation/#jumlah-data-dan-kondisinya","title":"Jumlah data dan kondisinya","text":"<ul> <li>Dataset user berisi 278.858 data pengguna dengan 3 kolom, Kolom Age memiliki banyak nilai kosong (sekitar 40% data tidak tersedia).</li> <li>Dataset book berisi 271.360 data buku dengan 8 kolom, terdapat beberapa missing value pada kolom Book-Author, Publisher, dan Image-URL-L.</li> <li>Dataset ratings Berisi 1.149.780 data rating buku dengan 3 kolom dan tidak ditemukan missing value pada tabel ini.</li> </ul> <p>Dataset ini terdiri dari tiga tabel utama yakni Users, Books, dan Ratings, yang saling berelasi melalui User-ID dan ISBN.</p>"},{"location":"projects/Book-recommendation/#variabel-pada-dataset","title":"Variabel pada dataset","text":"Dataset Variabel Deskripsi Users User-ID ID unik untuk setiap pengguna Location Lokasi pengguna Age Usia pengguna Books ISBN Nomor ISBN buku Book-Title Judul buku. Book-Author Nama penulis buku Year-Of-Publication Tahun terbit buku. Publisher Nama penerbit buku. Image-URL-S URL gambar sampul berukuran kecil. Image-URL-M URL gambar sampul berukuran sedang. Image-URL-L URL gambar sampul berukuran besar. Ratings User-ID ID pengguna yang memberikan rating. ISBN ISBN buku yang dinilai. Book-Rating Rating yang diberikan (0 untuk implicit, 1-10 untuk explicit rating)."},{"location":"projects/Book-recommendation/#exploratory-data-analysis-eda-univariate-exploratory-data-analysis","title":"Exploratory Data Analysis (EDA) - Univariate Exploratory Data Analysis","text":""},{"location":"projects/Book-recommendation/#dataset-buku","title":"Dataset Buku","text":"<ul> <li>Variabel ISBN merupakan kode unik yang digunakan untuk mengidentifikasi setiap buku secara individual. Dalam dataset ini, seluruh 271.360 baris memiliki nilai ISBN yang unik tanpa nilai kosong.</li> <li>Variabel Book Title merupakan judul buku. Dari 271.360 data, terdapat 242.135 judul unik, menunjukkan adanya beberapa buku yang memiliki judul yang sama (kemungkinan edisi berbeda atau re-publish). Judul yang paling sering muncul antara lain Selected Poems, Little Women, dan Wuthering Heights.</li> <li>Variabel Book Author menampilkan nama penulis dari setiap buku. Terdapat 102.022 penulis unik dan hanya 2 nilai yang hilang. Penulis yang paling sering muncul dalam dataset ini adalah Agatha Christie, William Shakespeare, dan Stephen King, yang masing-masing memiliki ratusan judul.</li> <li>Variabel Year of publication merupakan tahun terbit buku yang awalnya bertipe objek dan telah dikonversi menjadi numerik. Rentangnya sangat luas (0 hingga 2050), menunjukkan adanya outlier atau data error. Tahun yang paling umum muncul adalah antara 1998 hingga 2002.</li> <li>Variabel Publisher menunjukkan penerbit buku. Terdapat 16.807 penerbit unik dengan hanya 2 data yang hilang. Beberapa penerbit yang paling banyak muncul adalah Harlequin, Silhouette, dan Pocket.</li> <li>Variabel Image URL merupakan URL gambar sampul buku dalam tiga ukuran berbeda. Kolom ini tidak memiliki nilai kosong, kecuali Image-URL-L yang memiliki 3 missing value. Data ini bersifat pelengkap dan tidak terlalu dibutuhkan untuk sistem rekomendasi ini.</li> </ul>"},{"location":"projects/Book-recommendation/#dataset-pengguna","title":"Dataset Pengguna","text":"<ul> <li>Variabel User-ID terdapat 278.858 nilai unik pada kolom User-ID, menandakan bahwa setiap pengguna dalam dataset bersifat unik. Tidak ditemukan nilai yang hilang pada kolom ini.</li> <li>Variabel Location terdapat 57.339 lokasi unik dalam kolom Location, yang menunjukkan keragaman geografis pengguna. Lokasi yang paling sering muncul adalah London, England, United Kingdom sebanyak 2.506 kali, diikuti oleh Toronto, Ontario, Canada dan Sydney, New South Wales, Australia. Tidak terdapat data yang hilang pada kolom ini.</li> <li>Variabel Age, Dari total data, hanya 168.096 (sekitar 60%) yang memiliki nilai usia. Rata-rata usia pengguna adalah sekitar 35 tahun dengan simpangan baku 14,43 tahun. Terdapat nilai ekstrim seperti usia minimum 0 tahun dan maksimum 244 tahun yang kemungkinan merupakan kesalahan input atau outlier.</li> </ul>"},{"location":"projects/Book-recommendation/#dataset-rating","title":"Dataset Rating","text":"<ul> <li>Variabel User-ID terdapat 105.283 pengguna unik dalam dataset ini, dan tidak ditemukan nilai yang hilang pada kolom User-ID.</li> <li>Variabel ISBN, jumlah ISBN unik yang tercatat adalah 340.556. ISBN yang paling sering muncul adalah 0971880107 sebanyak 2.502 kali, diikuti oleh 0316666343 sebanyak 1.295 kali. Tidak ada nilai kosong pada kolom ini.</li> <li>Variabel Book Rating memiliki 1.149.780 entri dengan nilai rata-rata 2.87 dan standar deviasi sebesar 3.85. Nilai rating berkisar antara 0 hingga 10. Sebanyak 716.109 entri (sekitar 62%) memiliki rating 0, yang biasanya menandakan tidak ada rating yang diberikan. Rating 10 muncul sebanyak 78.610 kali, menunjukkan sejumlah pengguna memberikan skor maksimal. Distribusi lainnya menunjukkan peningkatan jumlah data seiring naiknya rating, terutama dari nilai 5 hingga 8.</li> </ul>"},{"location":"projects/Book-recommendation/#beberapa-variabel-yang-perlu-perbaikan","title":"Beberapa Variabel yang perlu perbaikan","text":"Dataset Variabel Masalah Ditemukan Tindakan Preprocessing Buku Book-Title Terdapat judul buku yang sama Hapus judul buku yang sama Buku Book-Author Terdapat 2 missing value Hapus baris dengan nilai kosong Buku Publisher Terdapat 2 missing value Hapus baris dengan nilai kosong Buku Year-Of-Publication Nilai tidak valid: 0 dan &gt; 2025 Menggantinya dengan nilai median Buku Image-URL Variabel tidak dibutuhkan Menghapus variabel (drop) Pengguna Age Nilai outlier: 0 dan &gt; 100 Menggantinya dengan nilai median"},{"location":"projects/Book-recommendation/#data-preparation","title":"Data Preparation","text":"<p>Pada tahap ini dilakukan serangkaian proses pembersihan dan penyiapan data sebelum masuk ke tahap pemodelan. Data preparation penting untuk memastikan data yang digunakan sudah bersih, konsisten, relevan, dan siap mendukung performa model. Berikut langkah-langkah data preparation yang dilakukan:</p>"},{"location":"projects/Book-recommendation/#handling-missing-value","title":"Handling Missing Value","text":""},{"location":"projects/Book-recommendation/#book-author-dan-publisher","title":"Book-Author dan Publisher","text":"<p>Baris data yang memiliki nilai kosong pada kolom <code>Book-Author</code> atau <code>Publisher</code> dihapus, karena kedua atribut ini mengandung informasi penting yang digunakan dalam sistem rekomendasi berbasis konten. Kehilangan informasi ini dapat menyebabkan penurunan akurasi rekomendasi.</p> <pre><code>book = book[book['Book-Author'].notnull()]\nbook = book[book['Publisher'].notnull()]\n</code></pre>"},{"location":"projects/Book-recommendation/#year-of-publication","title":"Year-Of-Publication","text":"<p>Nilai <code>Year-Of-Publication</code> yang tidak valid (bernilai 0 atau lebih dari 2025) diganti dengan <code>NaN</code>, lalu diisi menggunakan median tahun publikasi yang valid. Hal ini dilakukan untuk menjaga konsistensi data dan menghindari bias pada fitur tahun terbit yang dapat mempengaruhi kualitas rekomendasi.</p> <pre><code>book.loc[(book['Year-Of-Publication'] == 0) | (book['Year-Of-Publication'] &gt; 2025), 'Year-Of-Publication'] = np.nan\nmedian_year = book['Year-Of-Publication'].median()\nbook['Year-Of-Publication'].fillna(median_year, inplace=True)\n</code></pre>"},{"location":"projects/Book-recommendation/#age","title":"Age","text":"<p>Data pengguna dengan <code>Age</code> di bawah 5 tahun atau di atas 100 tahun dianggap tidak realistis dan dapat menjadi outlier yang merusak analisis. Oleh karena itu, nilai yang tidak masuk akal diganti menjadi <code>NaN</code>, kemudian diisi dengan median usia agar distribusi umur pengguna tetap representatif.</p> <pre><code>user.loc[(user['Age'] &lt; 5) | (user['Age'] &gt; 100), 'Age'] = np.nan\nmedian_age = user['Age'].median()\nuser['Age'].fillna(median_age, inplace=True)\n</code></pre>"},{"location":"projects/Book-recommendation/#handling-duplicates","title":"Handling Duplicates","text":""},{"location":"projects/Book-recommendation/#book-title","title":"Book-Title","text":"<p>Duplikasi data berdasarkan <code>Book-Title</code> dapat menyebabkan bias dalam proses training model, seperti pemberian bobot lebih terhadap buku tertentu. Oleh karena itu, dilakukan penghapusan data duplikat agar sistem rekomendasi tidak berat sebelah.</p> <pre><code>book = book.drop_duplicates(subset=['Book-Title']).reset_index(drop=True)\n</code></pre>"},{"location":"projects/Book-recommendation/#feature-reduction","title":"Feature Reduction","text":""},{"location":"projects/Book-recommendation/#penghapusan-kolom-gambar","title":"Penghapusan Kolom Gambar","text":"<p>Kolom <code>Image-URL-S</code>, <code>Image-URL-M</code>, dan <code>Image-URL-L</code> tidak digunakan dalam proses pemodelan berbasis teks dan rating. Menghapus fitur yang tidak relevan membantu mengurangi noise dan mempercepat proses training model.</p> <pre><code>book.drop(['Image-URL-S', 'Image-URL-M', 'Image-URL-L'], axis=1, inplace=True)\n</code></pre>"},{"location":"projects/Book-recommendation/#content-based-filtering-preparation","title":"Content-Based Filtering Preparation","text":""},{"location":"projects/Book-recommendation/#ekstraksi-fitur-text-data","title":"Ekstraksi Fitur Text Data","text":"<p>Untuk pendekatan content-based filtering, diperlukan representasi teks dari buku. Oleh karena itu, kolom <code>Book-Title</code>, <code>Book-Author</code>, dan <code>Publisher</code> digabungkan menjadi satu kolom <code>text_data</code>, yang nantinya diolah lebih lanjut menggunakan teknik pembelajaran representasi teks.</p> <pre><code>text_data = book['Book-Title'] + ' ' + book['Book-Author'] + ' ' + book['Publisher']\n</code></pre>"},{"location":"projects/Book-recommendation/#tokenisasi-dan-training-word2vec","title":"Tokenisasi dan Training Word2Vec","text":"<p>Model Word2Vec dilatih menggunakan data tokenisasi <code>text_data</code>. Word2Vec membantu merepresentasikan teks dalam bentuk vektor numerik yang menangkap hubungan semantik antar kata, sehingga model rekomendasi dapat memahami konteks konten lebih baik.</p> <pre><code>sentences = [text.split() for text in text_data]\nmodel = Word2Vec(sentences, vector_size=100, window=5, min_count=1)\n</code></pre>"},{"location":"projects/Book-recommendation/#collaborative-filtering-preparation","title":"Collaborative Filtering Preparation","text":""},{"location":"projects/Book-recommendation/#filter-data-ratings","title":"Filter Data Ratings","text":"<p>Filtering data rating dilakukan untuk memastikan bahwa hanya data yang cukup sering muncul yang digunakan dalam training. User atau buku dengan sedikit rating kurang memberikan informasi berguna untuk membangun model collaborative filtering yang andal.</p> <pre><code>filtered_ratings = rating[\n    (rating['User-ID'].isin(rating['User-ID'].value_counts()[rating['User-ID'].value_counts() &gt; 20].index)) &amp;\n    (rating['ISBN'].isin(rating['ISBN'].value_counts()[rating['ISBN'].value_counts() &gt; 20].index))\n]\n</code></pre>"},{"location":"projects/Book-recommendation/#encode-label","title":"Encode Label","text":"<p>Data rating perlu dikonversi ke dalam format standar yang bisa diproses oleh library rekomendasi (dalam hal ini Surprise). Encoding label memastikan bahwa <code>User-ID</code> dan <code>ISBN</code> dalam format numerik, dan skala rating didefinisikan dengan benar (0-10).</p> <pre><code>reader = Reader(rating_scale=(0, 10))\ndata = Dataset.load_from_df(filtered_ratings[['User-ID', 'ISBN', 'Book-Rating']], reader)\n</code></pre>"},{"location":"projects/Book-recommendation/#split-data","title":"Split Data","text":"<p>Data dibagi menjadi set pelatihan (<code>trainset</code>) dan pengujian (<code>testset</code>) untuk memungkinkan validasi model secara objektif. Dengan memisahkan data, kita dapat mengevaluasi performa model terhadap data yang belum pernah dilihat sebelumnya.</p> <pre><code>trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n</code></pre>"},{"location":"projects/Book-recommendation/#hasil-setelah-data-preparation","title":"Hasil Setelah Data Preparation","text":"Dataset Jumlah Data Fitur Keterangan Books 242.132 ISBN, Book-Title, Book-Author, Year-Of-Publication, Publisher Tidak ada missing value pada semua kolom Users 278.858 User-ID, Location, Age Tidak ada missing value setelah pengisian median pada kolom Age"},{"location":"projects/Book-recommendation/#modeling-and-results","title":"Modeling and Results","text":"<p>Pada tahap ini, sistem rekomendasi dikembangkan menggunakan dua pendekatan berbeda, yaitu Content-Based Filtering dan Collaborative Filtering. Setiap pendekatan menghasilkan daftar rekomendasi Top-N buku untuk pengguna, berdasarkan mekanisme kerja dan parameter model yang telah ditentukan.</p>"},{"location":"projects/Book-recommendation/#1-content-based-filtering-dengan-word2vec-dan-cosine-similarity","title":"1. Content-Based Filtering dengan Word2Vec dan Cosine Similarity","text":"<p>Pada pendekatan Content-Based Filtering, sistem rekomendasi dibangun berdasarkan kemiripan konten antar buku. Representasi buku dibentuk menggunakan teknik Word2Vec, dan kemiripan antar buku dihitung menggunakan cosine similarity.</p>"},{"location":"projects/Book-recommendation/#cara-kerja-model","title":"Cara Kerja Model","text":"<ul> <li>Menggabungkan teks dari kolom <code>Book-Title</code>, <code>Book-Author</code>, dan <code>Publisher</code> menjadi satu kolom teks gabungan.</li> <li>Melakukan tokenisasi teks menjadi daftar kata.</li> <li>Melatih model Word2Vec untuk menghasilkan vektor representasi tiap kata dengan parameter utama:</li> <li><code>vector_size=100</code>: Dimensi vektor embedding.</li> <li><code>window=5</code>: Ukuran jendela konteks.</li> <li><code>min_count=1</code>: Kata dengan frekuensi minimal 1 disertakan.</li> <li>Untuk setiap buku, menghasilkan vektor representasi dengan mengambil rata-rata vektor kata-katanya.</li> <li>Mengukur kemiripan antar buku menggunakan cosine similarity.</li> <li>Menyusun rekomendasi Top-5 buku dengan skor cosine similarity tertinggi terhadap buku input.</li> </ul>"},{"location":"projects/Book-recommendation/#output-rekomendasi-contoh","title":"Output Rekomendasi (Contoh)","text":"ISBN Title Author Publisher Similarity Score 0393045218 The Mummies of Urumchi E. J. W. Barber W. W. Norton &amp; Company 1.00000 3791535714 Die Schildb\u00fcrger Erich K\u00e4stner Dressler Verlag 0.99991 033037401X Midwinter of the Spirit Phil Rickman Pan Publishing 0.99990 0965813509 The Throne of Bones Brian McNaughton Terminal Fright 0.99990 0316734500 The Bookseller of Kabul Asne Seierstad Little, Brown 0.99990"},{"location":"projects/Book-recommendation/#kelebihan","title":"Kelebihan","text":"<ul> <li>Dapat memberikan rekomendasi hanya berdasarkan konten buku, tanpa bergantung pada data pengguna lain.</li> <li>Cocok untuk mengatasi masalah cold-start pada buku baru.</li> </ul>"},{"location":"projects/Book-recommendation/#kekurangan","title":"Kekurangan","text":"<ul> <li>Hanya dapat merekomendasikan buku yang mirip dengan buku yang sudah diketahui.</li> <li>Kualitas rekomendasi bergantung pada kelengkapan dan akurasi metadata buku.</li> </ul>"},{"location":"projects/Book-recommendation/#2-collaborative-filtering-dengan-svd-singular-value-decomposition","title":"2. Collaborative Filtering dengan SVD (Singular Value Decomposition)","text":"<p>Pada pendekatan Collaborative Filtering, sistem rekomendasi dikembangkan menggunakan teknik Matrix Factorization dengan algoritma Singular Value Decomposition (SVD). Model ini memanfaatkan pola interaksi (rating) antara pengguna dan item.</p>"},{"location":"projects/Book-recommendation/#cara-kerja-model_1","title":"Cara Kerja Model","text":"<ul> <li>Menggunakan library Surprise untuk memproses dataset <code>User-ID</code>, <code>ISBN</code>, dan <code>Book-Rating</code>.</li> <li>Membagi dataset menjadi trainset dan testset dengan rasio 80:20.</li> <li>Melakukan Grid Search untuk menemukan kombinasi parameter terbaik dengan evaluasi menggunakan Root Mean Square Error (RMSE):</li> <li><code>n_factors</code>: Jumlah faktor laten (eksperimen 50 dan 100).</li> <li><code>lr_all</code>: Learning rate umum (eksperimen 0.005 dan 0.01).</li> <li><code>reg_all</code>: Regularisasi umum (eksperimen 0.02 dan 0.1).</li> <li>Melatih model SVD terbaik berdasarkan hasil Grid Search pada data training.</li> <li>Menggunakan model terlatih untuk memprediksi rating buku yang belum pernah dibaca oleh pengguna.</li> <li>Menyusun rekomendasi Top-5 buku dengan prediksi rating tertinggi.</li> </ul>"},{"location":"projects/Book-recommendation/#output-rekomendasi-contoh_1","title":"Output Rekomendasi (Contoh)","text":""},{"location":"projects/Book-recommendation/#sample-user-id-11676","title":"Sample User ID: 11676","text":"ISBN Book Title Book Author Year of Publication Publisher Predicted Rating 193156146X The Time Traveler's Wife Audrey Niffenegger 2003.0 MacAdam/Cage Publishing 10.00 0553582143 Body of Lies Iris Johansen 2003.0 Bantam 10.00 0345413881 Dr. Death (Alex Delaware Novels (Paperback)) Jonathan Kellerman 2001.0 Ballantine Books 10.00 0380720132 The Mystery of the Cupboard (Indian in the Cupboard Adventures) Lynne Reid Banks 1999.0 HarperTrophy 9.99 2253044903 Le Parfum : Histoire d'un meurtrier Patrick S\u00fcskind 1988.0 LGF 9.95"},{"location":"projects/Book-recommendation/#kelebihan_1","title":"Kelebihan","text":"<ul> <li>Dapat menemukan hubungan tersembunyi antar buku dari pola rating pengguna.</li> <li>Memberikan rekomendasi lebih beragam dibandingkan content-based filtering.</li> </ul>"},{"location":"projects/Book-recommendation/#kekurangan_1","title":"Kekurangan","text":"<ul> <li>Membutuhkan data interaksi pengguna yang cukup banyak untuk performa optimal.</li> <li>Kurang efektif pada kasus cold-start untuk pengguna baru atau buku baru.</li> </ul>"},{"location":"projects/Book-recommendation/#evaluasi","title":"Evaluasi","text":"<p>Pada tahap evaluasi ini, digunakan metrik yang sesuai dengan pendekatan masing-masing model rekomendasi.</p>"},{"location":"projects/Book-recommendation/#1-evaluasi-content-based-filtering-word2vec","title":"1. Evaluasi Content-Based Filtering (Word2Vec)","text":"<p>Pada model Content-Based Filtering menggunakan Word2Vec, dilakukan evaluasi dengan metode Precision secara manual. Precision digunakan untuk mengukur tingkat relevansi hasil rekomendasi berdasarkan penilaian manual.</p>"},{"location":"projects/Book-recommendation/#metrik-yang-digunakan-precision-manual-evaluation","title":"Metrik yang Digunakan: Precision (Manual Evaluation)","text":"<p>Formula Precision:</p> <p></p> <p>Keterangan: - Item relevan: Item rekomendasi yang dinilai sesuai berdasarkan kesamaan konten (judul, penulis, atau penerbit). - N: Jumlah total rekomendasi yang dievaluasi.</p>"},{"location":"projects/Book-recommendation/#metode-evaluasi","title":"Metode Evaluasi","text":"<ol> <li>Mengambil 5 hasil rekomendasi teratas dari model Content-Based Filtering.</li> <li>Menilai secara manual kesesuaian setiap rekomendasi dengan input awal.</li> <li>Menghitung rasio jumlah rekomendasi relevan terhadap total rekomendasi.</li> </ol>"},{"location":"projects/Book-recommendation/#hasil-evaluasi","title":"Hasil Evaluasi","text":"<p>Contoh evaluasi untuk buku input \"The Mummies of Urumchi\":</p> Judul Buku yang Direkomendasikan Relevan? The Mummies of Urumchi \u2714\ufe0f Die Schildb\u00c3?\u00c2\u00bcrger. \u2714\ufe0f Midwinter of the Spirit \u2714\ufe0f The throne of bones \u2714\ufe0f The Bookseller of Kabul \u2714\ufe0f <ul> <li>Jumlah rekomendasi relevan: 5 dari 5</li> <li>Precision: 100%</li> </ul>"},{"location":"projects/Book-recommendation/#2-evaluasi-collaborative-filtering-svd","title":"2. Evaluasi Collaborative Filtering (SVD)","text":"<p>Pada model Collaborative Filtering menggunakan algoritma SVD (Singular Value Decomposition), digunakan metrik evaluasi Root Mean Squared Error (RMSE).</p>"},{"location":"projects/Book-recommendation/#metrik-yang-digunakan-rmse","title":"Metrik yang Digunakan: RMSE","text":"<p>Formula RMSE:</p> <p></p> <p>Keterangan:</p> <p></p> <p>RMSE mengukur seberapa jauh prediksi model dari nilai aktual; semakin kecil RMSE, semakin baik performa model.</p>"},{"location":"projects/Book-recommendation/#hasil-evaluasi_1","title":"Hasil Evaluasi","text":"<ul> <li>Best RMSE dari hasil Grid Search: 3.486.</li> <li>Parameter terbaik yang diperoleh:</li> <li>n_factors: 100</li> <li>lr_all: 0.005</li> <li>reg_all: 0.1</li> </ul>"},{"location":"projects/Book-recommendation/#kesimpulan","title":"Kesimpulan","text":"<ul> <li>Content-Based Filtering menghasilkan Precision yang sangat tinggi (100%), menunjukkan akurasi tinggi dalam merekomendasikan buku serupa.</li> <li>Collaborative Filtering (SVD) memberikan RMSE yang cukup kecil, menunjukkan ketepatan model dalam memprediksi preferensi pengguna berdasarkan pola rating.</li> </ul> <p>Kedua pendekatan memiliki keunggulannya masing-masing: - Content-Based Filtering lebih cocok untuk menemukan item serupa dari konten. - Collaborative Filtering lebih efektif untuk personalisasi berdasarkan perilaku pengguna.</p>"},{"location":"projects/Gamble-comment-detector/","title":"Gamble Comment Detector","text":"<p> An intelligent machine learning system with automated MLOps pipeline for detecting gambling-related content in user comments using natural language processing techniques. </p>"},{"location":"projects/Gamble-comment-detector/#automated-ml-pipeline-mlops","title":"Automated ML Pipeline (MLOps)","text":"<p>This project implements a complete MLOps pipeline using GitHub Actions that automatically handles the entire machine learning lifecycle:</p>"},{"location":"projects/Gamble-comment-detector/#pipeline-stages","title":"Pipeline Stages","text":"Stage Description Tools Used Environment Setup Python 3.9, dependencies installation <code>setup-python@v4</code>, <code>pip</code> Data Management Auto-generate dummy data if missing Custom Python script Model Training Train ML model with latest data <code>scikit-learn</code>, <code>joblib</code> Model Evaluation Generate performance metrics and reports Custom evaluation script Artifact Management Version control for model files Git commits, <code>upload-artifact@v4</code> Auto Deployment Deploy to Hugging Face Spaces Git LFS, HF Spaces API"},{"location":"projects/Gamble-comment-detector/#pipeline-triggers","title":"Pipeline Triggers","text":"<ul> <li>Automatic : Every push to <code>main</code> branch</li> <li>Manual : Workflow dispatch for on-demand runs</li> </ul>"},{"location":"projects/Gamble-comment-detector/#project-structure","title":"Project Structure","text":"<pre><code>gamble-comment-detector/\n\u251c\u2500\u2500 \ud83d\udcc1 .github/\n\u2502   \u2514\u2500\u2500 workflows/\n\u2502       \u2514\u2500\u2500 pipeline.yml   # Pipeline Configuration\n\u251c\u2500\u2500 \ud83d\udcc1 app/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 main.py            # FastAPI application\n\u251c\u2500\u2500 \ud83d\udcc1 data/\n\u2502   \u2514\u2500\u2500 comments.csv       # Training dataset\n\u251c\u2500\u2500 \ud83d\udcc1 model/\n\u2502   \u251c\u2500\u2500 eval_report.json   # Automated evaluation metrics\n\u2502   \u251c\u2500\u2500 saved_model.joblib # Auto-generated ML model\n\u2502   \u2514\u2500\u2500 vectorizer.joblib  # Auto-generated text vectorizer\n\u251c\u2500\u2500 \ud83d\udcc1 notebooks/\n\u2502   \u2514\u2500\u2500 Baseline.ipynb     # Jupyter notebook for experimentation\n\u251c\u2500\u2500 \ud83d\udcc1 scripts/\n\u2502   \u2514\u2500\u2500 generate_dummy_data.py  # Auto data generation\n\u251c\u2500\u2500 \ud83d\udcc1 src/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 evaluate.py        # Automated model evaluation\n\u2502   \u251c\u2500\u2500 inference.py       # Prediction logic\n\u2502   \u251c\u2500\u2500 preprocessing.py   # Data preprocessing\n\u2502   \u2514\u2500\u2500 train.py          # Automated model training\n\u251c\u2500\u2500 app.py                # Main application entry point\n\u251c\u2500\u2500 requirements.txt      # Python dependencies\n\u2514\u2500\u2500 README.md            # This file\n</code></pre>"},{"location":"projects/Gamble-comment-detector/#api-endpoints","title":"API Endpoints","text":"Method Endpoint Description <code>POST</code> <code>/predict</code> Analyze a single comment <code>POST</code> <code>/predict/batch</code> Analyze multiple comments <code>GET</code> <code>/health</code> Health check endpoint <code>GET</code> <code>/model/info</code> Get model information and version"},{"location":"projects/Gamble-comment-detector/#example-api-usage","title":"Example API Usage","text":"<p>Single Prediction:</p> <pre><code>POST /predict\n{\n    \"text\": \"I just won big at the casino last night!\"\n}\n\nResponse:\n{\n    \"is_gambling\": true,\n    \"confidence\": 0.87,\n    \"model_version\": \"v1.2.3\",\n    \"timestamp\": \"2024-01-15T10:30:00Z\"\n}\n</code></pre>"},{"location":"projects/Gamble-comment-detector/#mlops-workflow-details","title":"MLOps Workflow Details","text":""},{"location":"projects/Gamble-comment-detector/#github-actions-pipeline-configuration","title":"GitHub Actions Pipeline Configuration","text":"<p>The automated pipeline (<code>pipeline.yml</code>) includes:</p> <pre><code># Key Pipeline Steps\n1. Environment Setup (Python 3.9)\n2. Dependency Installation\n3. Automated Model Training\n4. Performance Evaluation\n5. Model Artifact Versioning\n6. Auto-Deployment to HF Spaces\n</code></pre>"},{"location":"projects/Gamble-comment-detector/#required-secrets","title":"Required Secrets","text":"<p>For the pipeline to work, set these GitHub repository secrets:</p> <ul> <li><code>HF_TOKEN</code>: Hugging Face API token for deployment</li> </ul>"},{"location":"projects/Gamble-comment-detector/#development","title":"Development","text":""},{"location":"projects/Gamble-comment-detector/#local-development","title":"Local Development","text":"<pre><code># Run tests\npytest tests/ -v\n\n# Code formatting\nblack src/ app/\nflake8 src/ app/\n\n# Generate dummy data\npython scripts/generate_dummy_data.py\n</code></pre>"},{"location":"projects/Gamble-comment-detector/#pipeline-testing","title":"Pipeline Testing","text":"<pre><code># Test pipeline locally (requires Act)\nact -j train-and-deploy\n</code></pre>"},{"location":"projects/Gamble-comment-detector/#contributing","title":"Contributing","text":"<p>We welcome contributions! The automated pipeline will test your changes automatically.</p>"},{"location":"projects/Gamble-comment-detector/#how-to-contribute","title":"How to Contribute","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch (<code>git checkout -b feature/-------</code>)</li> <li>Commit your changes (<code>git commit -m '-----------'</code>)</li> <li>Push to the branch (<code>git push origin feature/---------</code>)</li> <li>Open a Pull Request</li> </ol>"},{"location":"projects/Gamble-comment-detector/#roadmap","title":"Roadmap","text":"<ul> <li>[x] \u2705 Basic ML model implementation</li> <li>[x] \u2705 FastAPI REST API</li> <li>[x] \u2705 Automated MLOps pipeline with GitHub Actions</li> <li>[x] \u2705 Auto-deployment to Hugging Face Spaces</li> <li>[x] \u2705 Model evaluation metrics and reporting</li> <li>[ ] \ud83d\udd04 A/B testing framework</li> <li>[ ] \ud83d\udd04 Model performance monitoring dashboard</li> <li>[ ] \ud83d\udd04 Advanced deep learning models</li> <li>[ ] \ud83d\udd04 Multi-language support</li> <li>[ ] \ud83d\udd04 Docker containerization</li> <li>[ ] \ud83d\udd04 Kubernetes deployment</li> </ul>"},{"location":"projects/Gamble-comment-detector/#live-demo","title":"Live Demo","text":"<p>Try the live model: Hugging Face Spaces</p> <p>Updated automatically with every model improvement!</p>"},{"location":"projects/Gamble-comment-detector/#license","title":"License","text":"<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>"},{"location":"projects/Gamble-comment-detector/#acknowledgments","title":"Acknowledgments","text":"<ul> <li>Thanks to all contributors who helped build this project</li> <li>Built with using FastAPI, scikit-learn, GitHub Actions, and Hugging Face</li> </ul>"},{"location":"projects/Gamble-comment-detector/#support","title":"Support","text":"<ul> <li>Found a bug? Open an issue</li> <li>Have a feature request? Start a discussion</li> <li>Pipeline Issues? Check Actions tab</li> </ul> <p> \u2b50 Don't forget to star this repository if you found it helpful! &lt;e"},{"location":"projects/Student-Performance/","title":"Laporan Proyek Machine Learning - Muh. Arsan Akbar","text":""},{"location":"projects/Student-Performance/#domain-proyek","title":"Domain Proyek","text":"<p>Pendidikan merupakan fondasi utama dalam membentuk sumber daya manusia yang kompeten dan berdaya saing tinggi, terutama dalam menghadapi tantangan globalisasi dan kemajuan teknologi. Kualitas pendidikan yang baik menjadi kunci dalam mencetak individu yang produktif dan mampu memberikan kontribusi positif terhadap masyarakat. Namun demikian, sistem pendidikan di berbagai negara, termasuk Indonesia, masih menghadapi tantangan besar, khususnya terkait dengan tingginya angka putus sekolah dan rendahnya tingkat retensi siswa (Tjandra et al., 2022). Permasalahan ini tidak hanya menghambat perkembangan sektor pendidikan, tetapi juga berdampak jangka panjang terhadap masa depan generasi muda.</p> <p>Salah satu penyebab utama dari tingginya angka putus sekolah adalah rendahnya kinerja akademik siswa. Ketika siswa mengalami kesulitan dalam memahami materi pelajaran dan tidak mencapai hasil belajar yang memadai, mereka lebih rentan untuk kehilangan motivasi dan akhirnya memilih keluar dari sistem pendidikan formal (Gusnina et al., 2022). Dalam konteks ini, diperlukan strategi preventif yang tepat untuk mengidentifikasi siswa yang berisiko dan memberikan intervensi secara dini (Ismanto et al., 2022).</p> <p>Penerapan teknologi seperti machine learning dalam dunia pendidikan memberikan peluang besar untuk mengatasi permasalahan tersebut. Salah satunya adalah dengan membangun sistem prediksi kinerja akademik siswa berdasarkan data historis dan karakteristik individual. Kinerja akademik sendiri merupakan indikator yang mencerminkan sejauh mana siswa berhasil mencapai tujuan pembelajaran dalam bidang tertentu. Dengan melakukan prediksi terhadap performa akademik, pendidik dapat memberikan bimbingan, sumber daya tambahan, serta intervensi yang disesuaikan dengan kebutuhan masing-masing siswa (Masangu et al., 2020).</p> <p>Lebih jauh lagi, kinerja akademik yang baik tidak hanya menentukan kesuksesan siswa di lingkungan sekolah, tetapi juga menjadi faktor penting dalam kesiapan memasuki dunia kerja. Siswa yang unggul secara akademik umumnya memiliki peluang yang lebih besar untuk memperoleh pekerjaan berkualitas dan memiliki jenjang karier yang lebih baik (Adane et al., 2023). Oleh karena itu, meningkatkan kinerja akademik siswa memiliki dampak luas, baik dari sisi pendidikan maupun kehidupan profesional mereka setelah lulus.</p> <p>Berdasarkan urgensi tersebut, proyek ini akan mengembangkan sistem prediksi kinerja akademik siswa menggunakan pendekatan machine learning, dengan memanfaatkan fitur-fitur seperti skor matematika, membaca, menulis, serta variabel sosiodemografis seperti gender, etnis, dan latar belakang pendidikan orang tua. Melalui pendekatan ini, diharapkan sekolah dan lembaga pendidikan dapat secara proaktif mendeteksi potensi permasalahan akademik dan menyediakan solusi berbasis data yang lebih efektif.</p> <p>Referensi:</p> <p>Tjandra, E., Kusumawardani, S. S., &amp; Ferdiana, R. (2022). Student performance prediction in higher education: A comprehensive review. AIP Conference Proceedings. https://doi.org/10.1063/5.0080187</p> <p>Gusnina, M., Wiharto, N., &amp; Salamah, U. (2022). Student performance prediction in Sebelas Maret University based on the Random Forest algorithm. Ing\u00e9nierie Des Syst\u00e8mes D Information, 27(3), 495\u2013501. https://doi.org/10.18280/isi.270317</p> <p>Ismanto, E., Ghani, H. A., Saleh, N. I. M., Amien, J. A., &amp; Gunawan, R. (2022). Recent systematic review on student performance prediction using backpropagation algorithms. TELKOMNIKA (Telecommunication Computing Electronics and Control), 20(3), 597. https://doi.org/10.12928/telkomnika.v20i3.21963</p> <p>Adane, M. D., Deku, J. K., &amp; Asare, E. K. (2023). Performance analysis of machine learning algorithms in prediction of student academic performance. Journal of Advances in Mathematics and Computer Science, 38(5), 74\u201386. https://doi.org/10.9734/jamcs/2023/v38i51762</p>"},{"location":"projects/Student-Performance/#business-understanding","title":"Business Understanding","text":"<p>Pendidikan adalah pilar utama pembangunan sumber daya manusia. Namun, tantangan serius masih dihadapi, terutama terkait dengan rendahnya kinerja akademik siswa yang dapat memicu putus sekolah. Oleh karena itu, pemanfaatan pendekatan prediktif berbasis machine learning dalam dunia pendidikan menjadi langkah yang strategis untuk mendeteksi potensi permasalahan akademik sejak dini.</p>"},{"location":"projects/Student-Performance/#problem-statements","title":"Problem Statements","text":"<ul> <li>Bagaimana memprediksi kinerja akademik siswa secara akurat berdasarkan data karakteristik tertentu?</li> <li>Fitur apa saja yang paling signifikan dan berpengaruh dalam menentukan performa akademik siswa?</li> </ul>"},{"location":"projects/Student-Performance/#goals","title":"Goals","text":"<ul> <li>Membangun model prediksi machine learning yang mampu memperkirakan kinerja akademik siswa secara akurat berdasarkan fitur-fitur yang tersedia.</li> <li>Mengidentifikasi fitur-fitur yang paling berkorelasi dan berkontribusi signifikan terhadap keberhasilan akademik siswa.</li> </ul>"},{"location":"projects/Student-Performance/#solution-statements","title":"Solution statements","text":"<ul> <li>Menerapkan algoritma KNeighborsRegressor, RandomForestRegressor dan AdaBoostRegressor untuk membuat model prediksi performa siswa</li> <li>Membuat fitur baru dari fitur yang ada (feature engineering), yaitu menggabungkan skor rata-rata dari tiga indikator penilaian utama untuk membentuk sebuah label yang baru. Fitur tersebut nantinya akan digunakan sebagai acuan untuk menilai fitur yang paling signifikan terhadap keberhasilan siswa.</li> <li>Menghitung Mean Squared Error masing-masing algoritma pada data train dan test untuk mencari model yang terbaik</li> </ul>"},{"location":"projects/Student-Performance/#data-understanding","title":"Data Understanding","text":"<p>Dataset yang digunakan dalam proyek ini adalah Student Performance Prediction Dataset yang bersumber dari platform Kaggle.</p> <p>Jumlah Data: Dataset ini terdiri dari 1000 baris (sampel siswa) dan 8 kolom (fitur).</p> <p>Kondisi Data: Berdasarkan analisis awal, dataset ini memiliki kondisi sebagai berikut: - Missing Value: Tidak terdapat nilai yang hilang (missing value) dalam dataset. - Outlier: Berdasarkan visualisasi distribusi fitur numerik, tidak terdeteksi adanya outlier ekstrem yang secara signifikan dapat mengganggu analisis atau pemodelan. Beberapa nilai ekstrem rendah pada skor matematika mungkin ada, namun dianggap sebagai variasi alami dalam performa siswa.</p> <p>Tautan Sumber Data: https://www.kaggle.com/datasets/rkiattisak/student-performance-in-mathematics/data</p> <p>Uraian Fitur: - <code>gender</code>: Merupakan jenis kelamin siswa, dengan nilai <code>male</code> (laki-laki) atau <code>female</code> (perempuan). - <code>race/ethnicity</code>: Menunjukkan latar belakang ras atau etnis siswa. Kategori ini dibagi menjadi lima kelompok: <code>group A</code>, <code>group B</code>, <code>group C</code>, <code>group D</code>, dan <code>group E</code>. - <code>parental level of education</code>: Menyatakan tingkat pendidikan tertinggi yang dicapai oleh orang tua atau wali siswa. Nilainya meliputi: <code>some high school</code>, <code>high school</code>, <code>some college</code>, <code>associate's degree</code>, <code>bachelor's degree</code>, dan <code>master's degree</code>. - <code>lunch</code>: Menunjukkan status subsidi makan siang siswa. Nilainya adalah <code>standard</code> (membayar penuh) atau <code>free/reduced</code> (gratis atau subsidi). - <code>test preparation course</code>: Menunjukkan apakah siswa telah menyelesaikan kursus persiapan ujian. Nilainya adalah <code>completed</code> atau <code>none</code>. - <code>math score</code>: Skor siswa dalam ujian standar mata pelajaran matematika. Nilainya berupa bilangan bulat dari 0 hingga 100. - <code>reading score</code>: Skor siswa dalam ujian standar mata pelajaran membaca. Nilainya berupa bilangan bulat dari 0 hingga 100. - <code>writing score</code>: Skor siswa dalam ujian standar mata pelajaran menulis. Nilainya berupa bilangan bulat dari 0 hingga 100.</p>"},{"location":"projects/Student-Performance/#exploratory-data-analysis-univariate-analysis","title":"Exploratory data analysis - Univariate Analysis","text":""},{"location":"projects/Student-Performance/#fitur-fitur-kategori","title":"Fitur-fitur Kategori","text":""},{"location":"projects/Student-Performance/#distribusi-gender","title":"Distribusi Gender","text":"Gender Count Percent Male 508 50.8% Female 492 49.2% <p>Jumlah siswa laki-laki (50.8%) dan perempuan (49.2%) hampir seimbang. Hal ini menunjukkan tidak adanya bias signifikan dalam representasi gender</p>"},{"location":"projects/Student-Performance/#distribusi-raceethnicity","title":"Distribusi Race/Ethnicity","text":"Race/Ethnicity Count Percent Group C 323 32.3% Group D 257 25.7% Group B 198 19.8% Group E 143 14.3% Group A 79 7.9% <p>Sebagian besar siswa berasal dari Group C (32.3%), diikuti oleh Group D (25.7%) dan Group B (19.8%). Group A dan E relatif lebih sedikit.</p>"},{"location":"projects/Student-Performance/#distribusi-parental-level-of-education","title":"Distribusi Parental Level of Education","text":"Parental Level of Education Count Percent Some college 224 22.4% High school 215 21.5% Associate's degree 204 20.4% Some high school 177 17.7% Bachelor's degree 105 10.5% Master's degree 75 7.5% <p>Mayoritas orang tua siswa memiliki tingkat pendidikan \u201csome college\u201d (22.4%), diikuti oleh \u201chigh school\u201d (21.5%) dan \u201cassociate's degree\u201d (20.4%). Sementara itu, hanya sebagian kecil orang tua yang memiliki gelar \u201cmaster\u2019s degree\u201d (7.5%). </p>"},{"location":"projects/Student-Performance/#distribusi-lunch","title":"Distribusi Lunch","text":"Lunch Type Count Percent Standard 660 66.0% Free/Reduced 340 34.0% <p>Sebanyak 66.0% siswa mendapatkan makan siang standar, sedangkan 34.0% menerima makan siang gratis atau diskon.</p>"},{"location":"projects/Student-Performance/#distribusi-test-preparation-course","title":"Distribusi Test Preparation Course","text":"Test Preparation Course Count Percent None 656 65.6% Completed 344 34.4% <p>Sebanyak 65.6% siswa tidak mengikuti kursus persiapan ujian, sedangkan 34.4% mengikuti.</p> <p>Kesimpulan</p> <p>Berdasarkan hasil eksplorasi data (EDA) terhadap variabel kategorikal, dapat disimpulkan bahwa distribusi siswa berdasarkan gender cukup seimbang, dengan proporsi laki-laki sebesar 50.8% dan perempuan 49.2%. Dari sisi latar belakang etnis, mayoritas siswa berasal dari group C (32.3%), diikuti oleh group D (25.7%) dan group B (19.8%), sementara group A dan E masing-masing hanya menyumbang 7.9% dan 14.3%. Latar belakang pendidikan orang tua menunjukkan bahwa sebagian besar berasal dari keluarga dengan tingkat pendidikan menengah, seperti \u201csome college\u201d (22.4%) dan \u201chigh school\u201d (21.5%). Hanya sedikit orang tua yang memiliki gelar magister (7.5%), yang menunjukkan bahwa sebagian besar siswa mungkin tidak mendapatkan dukungan akademik dari orang tua dengan pendidikan tinggi.</p> <p>Dari sisi ekonomi, sebanyak 66.0% siswa mendapatkan makan siang standar, sementara 34.0% menerima makan siang gratis atau bersubsidi, yang sering kali menjadi indikator kondisi sosial-ekonomi yang lebih rendah. Selain itu, hanya 34.4% siswa yang telah menyelesaikan kursus persiapan ujian, sedangkan 65.6% lainnya tidak mengikuti kursus tersebut. Hal ini menunjukkan bahwa sebagian besar siswa mungkin menghadapi keterbatasan dalam akses terhadap persiapan akademik tambahan.</p> <p>Secara keseluruhan, hasil ini memberikan gambaran bahwa faktor sosial-ekonomi, latar belakang pendidikan orang tua, serta akses terhadap fasilitas belajar tambahan dapat menjadi faktor penting yang memengaruhi performa akademik siswa. Analisis lanjutan sangat dianjurkan untuk melihat bagaimana variabel-variabel ini berkorelasi dengan hasil tes akademik seperti nilai matematika, membaca, dan menulis, guna memperoleh pemahaman yang lebih mendalam dan komprehensif.</p>"},{"location":"projects/Student-Performance/#fitur-fitur-numerikal","title":"Fitur-fitur Numerikal","text":"<p>Berdasarkan hasil eksplorasi data univariat terhadap fitur numerik yaitu math score, reading score, dan writing score, dapat disimpulkan bahwa distribusi ketiga skor tersebut cenderung mengikuti pola distribusi normal, meskipun terlihat sedikit condong ke kiri (left-skewed), khususnya pada skor matematika dan menulis. Sebagian besar nilai berada dalam kisaran 60 hingga 80, yang menunjukkan bahwa mayoritas siswa memiliki performa akademik yang cukup baik. Skor membaca menunjukkan distribusi yang paling simetris, serta memiliki konsentrasi nilai tinggi lebih banyak dibanding dua skor lainnya, mengindikasikan bahwa kemampuan membaca siswa secara umum lebih unggul. Sementara itu, skor matematika memiliki beberapa nilai rendah yang secara realita tidak dapat dianggap sebagai outlier, namun tidak terlalu signifikan. Secara keseluruhan, ketiga skor ini menunjukkan distribusi yang baik dan stabil.</p> <p>Kesimpulan</p> <ul> <li>Histogram pertama menampilkan distribusi nilai ujian matematika (math score). Terlihat bahwa distribusi nilai cenderung unimodal dan mendekati distribusi normal, meskipun terdapat sedikit skewness ke kiri (ekor distribusi memanjang ke arah nilai yang lebih rendah). Sebagian besar siswa memperoleh nilai antara 60 hingga 80, dengan puncak frekuensi berada di sekitar nilai 65-70. Terdapat beberapa siswa dengan nilai yang sangat rendah (di bawah 40) dan juga beberapa siswa dengan nilai yang sangat tinggi (di atas 90), namun jumlahnya relatif lebih sedikit dibandingkan dengan kelompok nilai tengah.</li> <li>Histogram kedua menyajikan distribusi nilai ujian membaca (reading score). Distribusi nilai membaca tampak lebih mendekati distribusi normal dibandingkan dengan nilai matematika. Puncak frekuensi berada di sekitar nilai 70-80, dan sebagian besar siswa memperoleh nilai antara 60 hingga 90. Sebaran nilai membaca juga terlihat sedikit lebih lebar dibandingkan dengan nilai matematika, mengindikasikan variasi performa membaca antar siswa yang mungkin lebih besar. Jumlah siswa dengan nilai sangat rendah (di bawah 40) dan sangat tinggi (di atas 95) juga relatif sedikit.</li> <li>Histogram ketiga menggambarkan distribusi nilai ujian menulis (writing score). Distribusi nilai menulis juga terlihat unimodal dengan puncak frekuensi di sekitar nilai 65-75. Sebagian besar siswa memperoleh nilai antara 55 hingga 85. Distribusi nilai menulis menunjukkan skewness negatif yang lebih jelas dibandingkan dengan nilai matematika, dengan ekor distribusi yang lebih panjang ke arah nilai yang lebih rendah. Ini mengindikasikan bahwa terdapat lebih banyak siswa yang memperoleh nilai di bawah rata-rata dibandingkan dengan siswa yang memperoleh nilai jauh di atas rata-rata.</li> </ul>"},{"location":"projects/Student-Performance/#exploratory-data-analysis-multivariate-analysis","title":"Exploratory data analysis - Multivariate Analysis","text":""},{"location":"projects/Student-Performance/#fitur-fitur-kategorical-terhadap-target","title":"Fitur-fitur Kategorical Terhadap Target","text":"<p> Siswa perempuan memiliki skor rata-rata sedikit lebih tinggi (\u00b170) dibandingkan siswa laki-laki (\u00b168). Karena selisihnya kecil, maka fitur ini memiliki pengaruh yang rendah terhadap rata-rata skor.</p> <p> Siswa yang mendapatkan makan siang standar memiliki skor rata-rata lebih tinggi (\u00b172) dibandingkan dengan siswa yang mendapatkan makan siang gratis (\u00b164). Hal ini menunjukkan bahwa status makan siang memiliki pengaruh yang cukup kuat terhadap rata-rata skor.</p> <p> Siswa dengan orang tua berpendidikan tinggi seperti bachelor\u2019s degree dan master\u2019s degree cenderung memiliki rata-rata skor lebih tinggi (\u00b171), sedangkan yang berasal dari orang tua dengan pendidikan some high school memiliki rata-rata skor lebih rendah (\u00b165). Meskipun terlihat ada tren, perbedaan antar kelompok tidak terlalu tajam, sehingga fitur ini tidak terlalu berpengaruh terhadap skor.</p> <p> Siswa yang menyelesaikan kursus persiapan tes memiliki skor rata-rata lebih tinggi (\u00b174) dibandingkan yang tidak mengikuti kursus (\u00b167). Hal ini menunjukkan bahwa kursus persiapan tes memiliki pengaruh yang cukup kuat terhadap peningkatan skor rata-rata.</p> <p> Kelompok E memiliki skor rata-rata tertinggi (\u00b176), sementara kelompok lain berkisar antara 67 hingga 71. Perbedaan ini menunjukkan adanya variasi, namun tidak konsisten meningkat atau menurun antar kelompok, sehingga fitur ini memiliki pengaruh yang rendah terhadap skor.</p> <p>Kesimpulan</p> <p>Hasil analisis menunjukkan bahwa variabel kategorikal seperti pendidikan orangtua,jenis kelamin, jenis makan siang, tingkat pendidikan orangtua, partisipasi kursus, dan ras sebenarnya tidak memberikan dampak yang signifikan terhadap nilai rata-rata skor siswa. Hal ini ditunjukkan dengan nilai rata rata skor untuk tiap-tiap variabel yang hanya berada di kisaran 60-75.</p>"},{"location":"projects/Student-Performance/#fitur-fitur-numerical-terhadap-target","title":"Fitur-fitur Numerical Terhadap Target","text":"<p> Fitur numerik menunjukkan hubungan linear yang kuat satu sama lain, dengan korelasi tertinggi antara reading score dan writing score. Average score sangat bergantung secara proporsional pada ketiga skor asli, dan hubungan linear ini memvalidasi penggunaannya sebagai metrik gabungan. </p> <p>Kesimpulan</p> <p>Analisis pair plot ini dengan jelas menunjukkan hubungan linear positif yang sangat kuat antara nilai matematika, membaca, dan menulis dengan rata-rata skor siswa. Selain itu, terdapat korelasi yang tinggi di antara ketiga nilai ujian itu sendiri. Temuan ini menggarisbawahi pentingnya ketiga mata pelajaran ini dalam menentukan performa akademik keseluruhan siswa. Model prediksi rata-rata skor kemungkinan akan sangat akurat jika menggunakan ketiga nilai ujian ini sebagai fitur. Tidak terlihat adanya pola non-linear yang signifikan atau outlier ekstrem yang perlu perhatian khusus dari visualisasi ini.</p>"},{"location":"projects/Student-Performance/#data-preparation","title":"Data Preparation","text":"<ul> <li> <p>Karena dataset menunjukkan kondisi yang bersih tanpa adanya nilai yang hilang dan tidak terdapat outlier signifikan yang dapat berdampak negatif, maka tidak dilakukan pengurangan data.</p> </li> <li> <p>Feature Engineering: Membuat fitur baru berupa rata rata score yang didapatkan dari hasil math score + reading score + writing score dibagi 3, hal tersebut dilakukan mengingat belum adanya target pada dataset, sehingga perlu dilakukan feature engineering untuk menghasilkan fitur baru yang relevan.</p> </li> <li> <p>Encoding fitur kategori: Feature encoding kategori seperti OneHotEncoder penting dilakukan karena sebagian besar algoritma machine learning tidak dapat menangani data kategorikal secara langsung. Mereka memerlukan input berupa angka, sedangkan beberapa fitur pada dataset tersebut berbentuk kategori, fitur fitur tersebut adalah gender, ras, level pendidikan orangtua, tipe makan siang, dan tes persiapan.</p> </li> <li> <p>Reduksi dimensi dengan PCA: Reduksi dimensi dengan PCA (Principal Component Analysis) diperlukan karena fitur math score, reading score, dan writing score menunjukkan korelasi tinggi satu sama lain, yang berarti terdapat redundansi informasi. PCA membantu menyederhanakan fitur-fitur tersebut menjadi beberapa komponen utama yang tetap mempertahankan sebagian besar informasi, sehingga dapat meningkatkan efisiensi model, mengurangi risiko overfitting, dan mempermudah visualisasi data. Selain itu, PCA juga membantu menghilangkan noise dan menjaga struktur data dalam dimensi yang lebih rendah. Oleh karena itu fitur math score, reading score, dan writing score dimasukkan kedalam proses PCA menjadi sebuah fitur yang bernama student performance.</p> </li> <li> <p>Train dan test split: Train-test split perlu dilakukan untuk mengevaluasi kinerja model secara objektif. Dengan membagi data menjadi data latih (train) dan data uji (test), kita dapat melatih model pada satu bagian data dan mengujinya pada data yang belum pernah dilihat sebelumnya. Hal ini penting untuk menilai kemampuan generalisasi model terhadap data baru dan mencegah overfitting, yaitu kondisi di mana model terlalu baik dalam menghafal data latih namun buruk dalam memprediksi data baru. Dalam kasus ini, data dibagi 90% untuk pelatihan dan 10% untuk pengujian, memberikan cukup data untuk pembelajaran sambil tetap menyisakan data yang representatif untuk evaluasi.</p> </li> <li> <p>Standarisasi: hal tersebut perlu dilakukan untuk menyamakan skala fitur numerik agar model machine learning dapat bekerja secara optimal. Fitur seperti student performance mungkin memiliki rentang nilai yang berbeda dibanding fitur lain, dan ini bisa menyebabkan model lebih condong atau berat sebelah terhadap fitur dengan nilai besar. Dengan standarisasi menggunakan StandardScaler, data diubah agar memiliki rata-rata 0 dan standar deviasi 1, sehingga semua fitur berada dalam skala yang seimbang. Ini sangat penting terutama untuk algoritma yang sensitif terhadap skala data seperti KNN, SVM, dan regresi linier. Hasil standarisasi menunjukkan bahwa data telah terpusat di sekitar nol dengan penyebaran standar yang seragam, memastikan proses pelatihan model menjadi lebih stabil dan akurat.</p> </li> </ul>"},{"location":"projects/Student-Performance/#modeling","title":"Modeling","text":"<p>Pada tahap ini dilakukan pengembangan model machine learning untuk memprediksi skor rata-rata siswa berdasarkan fitur-fitur input yang telah diproses sebelumnya. Tiga algoritma regresi digunakan, yaitu K-Nearest Neighbors (KNN), Random Forest Regressor, dan AdaBoost Regressor.</p> <ul> <li>K-Nearest Neighbors (KNN)</li> </ul> <p>K-Nearest Neighbors (KNN) adalah algoritma non-parametrik yang bekerja dengan cara membandingkan jarak antara data uji dengan seluruh data latih, lalu memilih k tetangga terdekat untuk melakukan prediksi. Nilai prediksi untuk regresi ditentukan dari rata-rata nilai target dari k tetangga terdekat tersebut. Model KNN digunakan dengan parameter n_neighbors=10 dan untuk parameter lainnya bernilai default. Kelebihan KNN adalah sederhana dan tidak membutuhkan proses pelatihan yang kompleks. Namun, KNN sangat sensitif terhadap skala fitur dan kurang efisien pada dataset besar. Model ini menghasilkan MSE (mean squared error) sebesar 0.0137 (train) dan 0.0113 (test).</p> <ul> <li>Random Forest</li> </ul> <p>Random Forest merupakan algoritma ensemble learning yang menggabungkan banyak pohon keputusan (decision trees) untuk meningkatkan akurasi prediksi. Setiap pohon dilatih pada subset data yang dipilih secara acak (bootstrap), dan hasil prediksi akhir diambil rata-rata dari semua pohon. Random Forest digunakan dengan n_estimators=50, max_depth=16, random_state=55, n_jobs=-1 serta parameter lain yang bernilai default. Algoritma ini mampu menangani data dengan fitur non-linear dan tidak sensitif terhadap skala fitur. Namun random forest memerlukan sumber daya komputasi besar dan kurang interpretatif. Hasil evaluasi menunjukkan performa terbaik dibanding model lain, dengan MSE sangat kecil yaitu 0.000009 (train) dan 0.000008 (test). Ini menunjukkan model sangat akurat dalam menangkap pola data.</p> <ul> <li>AdaBoost Regressor</li> </ul> <p>AdaBoost (Adaptive Boosting) bekerja dengan membentuk model ensemble dari sejumlah weak learners, biasanya decision tree berukuran kecil. Setiap model baru dibangun dengan fokus pada data yang salah diklasifikasikan oleh model sebelumnya. Hasil akhir prediksi merupakan kombinasi tertimbang dari seluruh model. AdaBoost digunakan dengan learning_rate=0.05 dan random_state=55 serta parameter lainnya yang bernilai default. Algoritma ini meningkatkan akurasi model dengan menggabungkan banyak prediktor sederhana, akan tetapi rentan terhadap data outlier dan noise. Hasil yang diperoleh cukup baik, dengan MSE 0.0024 (train) dan 0.0029 (test), namun masih kalah dari Random Forest.</p> <p>Kesimpulan</p> <p>Berdasarkan hasil evaluasi MSE pada data latih dan uji, Random Forest dipilih sebagai model terbaik karena menghasilkan error paling rendah di antara semua model yang diuji. Selain itu, model ini juga lebih stabil dan mampu menangani kompleksitas data tanpa mengalami overfitting.</p>"},{"location":"projects/Student-Performance/#evaluation","title":"Evaluation","text":"<p>Karena proyek ini merupakan kasus regresi, maka metrik evaluasi yang digunakan adalah Mean Squared Error (MSE). MSE mengukur rata-rata kuadrat selisih antara nilai aktual (y_true) dan nilai prediksi (y_pred). Semakin kecil nilai MSE, semakin akurat model dalam melakukan prediksi. Metrik ini cocok digunakan karena memberikan penalti yang lebih besar pada kesalahan prediksi yang jauh dari nilai sebenarnya. MSE dihitung menggunakan rumus berikut:</p> <p></p> <p>Cara kerja MSE adalah dengan menghitung selisih antara nilai aktual dan prediksi untuk setiap data, lalu mengkuadratkan selisih tersebut agar tidak ada nilai negatif dan memberi penalti lebih besar terhadap kesalahan prediksi yang jauh. Kemudian seluruh kuadrat error dijumlahkan dan dirata-ratakan.</p> <p>MSE efektif digunakan dalam regresi karena memberikan pemahaman seberapa besar rata-rata kesalahan model dalam satuan kuadrat dari target. Nilai MSE yang lebih rendah menunjukkan model yang lebih baik dalam memprediksi target.</p> <p>Hasil Evaluasi Model</p> <p>Berdasarkan hasil evaluasi terhadap tiga model, diperoleh hasil sebagai berikut: | Model        | Train MSE | Test MSE | |--------------|-----------|----------| | KNN          | 0.0137    | 0.0113   | | RandomForest | 0.000009  | 0.000008 | | Boosting     | 0.0024    | 0.0029   |</p> <p>Dari tabel di atas, terlihat bahwa Random Forest Regressor memiliki performa terbaik dengan nilai MSE terkecil baik pada data latih maupun data uji. Hal ini menunjukkan bahwa model ini mampu melakukan generalisasi dengan sangat baik, serta minim terhadap overfitting.</p> <p>Evaluasi Prediksi</p> <p>Untuk melihat kualitas prediksi lebih lanjut, dilakukan perbandingan antara nilai aktual (y_true) dan hasil prediksi dari ketiga model: | y_true | KNN  | RandomForest | Boosting | |--------|------|--------------|----------| | 56.3   | 60.3 | 56.3         | 56.7     | | 92.0   | 87.2 | 92.0         | 93.2     | | 72.0   | 73.5 | 72.0         | 70.4     | | 63.3   | 67.8 | 63.3         | 63.8     |</p> <p>Dari tabel tersebut, dapat dilihat bahwa hasil prediksi Random Forest paling konsisten mendekati nilai sebenarnya dibanding model lainnya. Hal ini menguatkan alasan pemilihan Random Forest sebagai model akhir.</p>"}]}